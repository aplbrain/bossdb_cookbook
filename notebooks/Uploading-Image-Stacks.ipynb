{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Image Stacks\n",
    "\n",
    "In this notebook, we will upload an image stack to BossDB as a dataset.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "You will need to have a directory full of images to upload, and they should:\n",
    "* Sort by their names, alphabetically (i.e., `0001.png`, `0002.png`, etc.)\n",
    "* The images should all have the same dimensions in the horizontal and vertical directions\n",
    "* There should be no missing tiles.\n",
    "\n",
    "If you are creating a new BossDB channel, you will also need to have `resource-manager` permissions on BossDB. If you don't have these permissions (perhaps you just created an account?), please email ingests@bossdb.org with information about your dataset. We will add the correct permissions, and we are also happy to help you run your ingest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell to install requirements:\n",
    "# !pip3 install pillow tqdm numpy\n",
    "\n",
    "# Get the latest version of intern:\n",
    "# !pip3 install git+https://github.com/jhuapl-boss/intern.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from intern import array\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "You can update the cell below to match your ingest preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to where the images live. Don't forget the extension! You can also\n",
    "# omit an extension if EVERY file in the directory will be an image for upload.\n",
    "PATH_TO_IMAGES = Path(\"/path/to/images/dataset1/\")\n",
    "IMAGE_EXTENSION = \".tiff\"\n",
    "\n",
    "# How many z-slices to upload at once.\n",
    "# For best performance, this number should be a multiple of 16. If you have a\n",
    "# lot of RAM, you can increase this number to, say, 64. If you start getting\n",
    "# out-of-memory errors, you can decrease this number.\n",
    "# Try to avoid reducing it below 16, but if you must, you will get the best \n",
    "# performance with 8 or 4.\n",
    "UPLOAD_INCREMENT = 16\n",
    "\n",
    "# Channel name.\n",
    "# This is entirely up to you; you should put all research for a single paper\n",
    "# in the same collection, and all channels that should be co-registered should\n",
    "# live in the same experiment. You should use one channel for each z-stack. For\n",
    "# more information, see [this video](https://youtu.be/gbbfWDThELU?t=81)\n",
    "BOSSDB_URI = \"bossdb://matelsky2022/notebook_tutorial/em\"\n",
    "\n",
    "\n",
    "# In ZYX order, the size of a voxel:\n",
    "VOXEL_SIZE = (40, 4, 4)\n",
    "\n",
    "# The size units of a voxel:\n",
    "VOXEL_UNITS = \"nanometers\"\n",
    "\n",
    "# The number of times to retry a chunk upload before failing. Set this higher\n",
    "# (perhaps ~10) if you are leaving the job unattended for a long time.\n",
    "RETRY_MAX = 1\n",
    "\n",
    "# Data-type of the image data.\n",
    "DTYPE = \"uint8\" # \"uint8\" or \"uint64\"\n",
    "\n",
    "# The source channel, if there is one. If there are multiple segmentation \n",
    "# channels and one imagery channel, then you can use this to specify the image\n",
    "# channel name. Otherwise, specify None:\n",
    "SOURCE_CHANNEL = None # \"image\" perhaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the ingest.\n",
    "\n",
    "If you are just running a regular ingest, you don't have to edit anything below\n",
    "this cell; just run the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of Z slices in the stack:\n",
    "image_paths = sorted(PATH_TO_IMAGES.glob(\"*\" + IMAGE_EXTENSION))\n",
    "num_z_slices = len(image_paths)\n",
    "\n",
    "assert len(image_paths) > 0, f\"No images found in the specified directory {PATH_TO_IMAGES}/*{IMAGE_EXTENSION}.\"\n",
    "\n",
    "# Get the size of the first image, which we will assume is the same size as all \n",
    "# other images:\n",
    "image = Image.open(image_paths[0])\n",
    "image_size = image.size\n",
    "\n",
    "shape_zyx = (num_z_slices, image_size[1], image_size[0])\n",
    "\n",
    "print(f\"Found {num_z_slices} z-slices in the stack, for a dataset shape of {shape_zyx}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SOURCE_CHANNEL:\n",
    "    boss_dataset = array(\n",
    "        BOSSDB_URI,\n",
    "        extents=shape_zyx,\n",
    "        dtype=DTYPE,\n",
    "        voxel_size=VOXEL_SIZE,\n",
    "        voxel_unit=VOXEL_UNITS,\n",
    "        create_new=True,\n",
    "        source_channel=SOURCE_CHANNEL,\n",
    "    )\n",
    "else:\n",
    "    boss_dataset = array(\n",
    "        BOSSDB_URI,\n",
    "        extents=shape_zyx,\n",
    "        dtype=DTYPE,\n",
    "        voxel_size=VOXEL_SIZE,\n",
    "        voxel_unit=VOXEL_UNITS,\n",
    "        create_new=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate in groups of UPLOAD_INCREMENT. If there are image tiles left over at\n",
    "# the end, they will be uploaded separately.\n",
    "for i in tqdm(range(0, shape_zyx[0], UPLOAD_INCREMENT)):\n",
    "    if i + UPLOAD_INCREMENT > shape_zyx[0]:\n",
    "        # We're at the end of the stack, so upload the remaining images.\n",
    "        images = [Image.open(path) for path in image_paths[i : shape_zyx[0]]]\n",
    "    else:\n",
    "        images = [Image.open(path) for path in image_paths[i : i + UPLOAD_INCREMENT]]\n",
    "    stacked = np.stack([np.array(image, dtype=DTYPE) for image in images], axis=0)\n",
    "\n",
    "    retry_count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            boss_dataset[\n",
    "                i : i + stacked.shape[0], 0 : stacked.shape[1], 0 : stacked.shape[2]\n",
    "            ] = stacked\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading chunk {i}-{i + stacked.shape[0]}: {e}\")\n",
    "            retry_count += 1\n",
    "            if retry_count > RETRY_MAX:\n",
    "                raise e\n",
    "            print(\"Retrying...\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the visualization link to view the data in Neuroglancer:\n",
    "print(boss_dataset.visualize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('scripting')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "410f6db90cc89b666adbd1b755ae7555dd227a2d7c11822f3d377845b87672a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
